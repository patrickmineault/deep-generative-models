{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Disentangled Representations with Semi-Supervised Deep Generative Models\n",
    "\n",
    "https://arxiv.org/pdf/1706.00400.pdf\n",
    "\n",
    "**Idea**: take a normal VAE, which is fully unsupervised, and add nodes which may or may not be observed. Easiest example is MNIST w/ or w/o labels:\n",
    "\n",
    "<img src=\"w5-assets/plate-model.png\" width=\"200\"/>\n",
    "\n",
    "Here, we have $z$ which are the latent variables, always unobserved, $x$ which is the digit in image form, always observed, and $y$ which is digit identity, which is sometimes observed.\n",
    "\n",
    "In the semi-supervised setting, when we have $y$ for some examples and not for others, the likelihood of the model factorizes into two subparts:\n",
    "\n",
    "<img src=\"w5-assets/L_all.png\" width=\"600\"/>\n",
    "\n",
    "The first part is just like a regular VAE, and so is \"easy\". The second part, just the supervised part of the model, is more annoying: \n",
    "\n",
    "<img src=\"w5-assets/L_sup.png\" width=\"750\"/>\n",
    "\n",
    "We need to be able to evaluate the quantity $q(z|x, y)$, but depending on the dependency structure of x, y and z this might not be straightforward. The solution is to re-express the objective in terms of $q(y, z|x)$ which we evaluate using importance sampling with a proposal distribution $q(z|x)$.  Note that this kind of trick only works when y is pretty low dimensional, otherwise importance sampling crashes and burns. More reading on importance sampling:\n",
    "\n",
    "https://statweb.stanford.edu/~owen/mc/Ch-var-is.pdf\n",
    "\n",
    "Implementation:\n",
    "\n",
    "https://github.com/probtorch/probtorch\n",
    "\n",
    "## Advantages of semi-supervision\n",
    "\n",
    "  * the supervised samples \"anchor\" the model, so that, for example, the model is no longer symmetric with respect to label permutations.\n",
    "  * the latent variables $y$ are meaningful because we've imposed meaning on them top down\n",
    "  * inference can be done with very few labels, e.g. <10% error rate on MNIST with 100 examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
