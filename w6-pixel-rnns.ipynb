{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel RNNs\n",
    "\n",
    "https://arxiv.org/pdf/1601.06759.pdf\n",
    "\n",
    "## Ingredients\n",
    "\n",
    "  * Predict the next pixel\n",
    "  * 256-way classification (easy multimodality)\n",
    "  * Context is everything at the top and to the left of a given pixel - or includes subsampled pixels in the multi-scale case\n",
    "  * Row and diagonal LSTMs\n",
    "  * Residual connections\n",
    "  \n",
    "## Row LSTMs\n",
    "\n",
    ">  An LSTM layer has an **input-to-state component** and a **recurrent state-to-state component** that together determine the four gates inside the LSTM core.  To enhance parallelization in the Row LSTM the input-to-state component is first computed for the entire two-dimensional input map; for this a k×1 convolution is used to follow the row-wise orientation of the LSTM itself.\n",
    "The convolution is masked to include only the valid context (see Section 3.4) and produces a tensor of size 4h×n×n, representing the four gate vectors for each position in the input map, where h is the number of output feature maps.\n",
    "\n",
    "In other words, there's the following set of passes:\n",
    "\n",
    "  * First, run a convolution over the entire input to get the input-to-state component. The kernel is a horizontal 2 pixel kernel  which is set up to be causal left to right, that is, it goes [left middle 0]\n",
    "  * Then run an LSTM top to bottom to get the state-to-state mapping. The LSTM has a convolutional component to it (3x1). This gives the whole thing a triangular-shaped receptive field.\n",
    "\n",
    "## Diagonal LSTMs\n",
    "\n",
    "Same, but with two skewing operations to get top-left to bottom-right and top-right to bottom-left mappings; then concatenated. This op has a larger receptive field (context is whole image basically).\n",
    "\n",
    "## Implementation\n",
    "\n",
    " * Most complete I've seen, in Lasagne: https://github.com/taimir/pixel-rnn-lasagne\n",
    " * Half-baked tensorflow implementation: https://github.com/carpedm20/pixel-rnn-tensorflow\n",
    " * Haven't seen PyTorch implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
